{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading libraries and imports\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics\n",
    "from sklearn import tree, svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "print('Finished loading libraries and imports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading and merging the data\n"
     ]
    }
   ],
   "source": [
    "df_matches = pd.read_csv(\n",
    "    'data/matchResults.csv').merge(pd.read_csv('data/matchLineups.csv'), on='Match ID')\n",
    "df_statistics = pd.read_csv('data/playerStats.csv')\n",
    "df_teams = pd.read_csv('data/teams.csv')\n",
    "print('Finished loading and merging the data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading functions\n"
     ]
    }
   ],
   "source": [
    "def clean_matches_dataset():\n",
    "    df = pd.DataFrame()\n",
    "    df['match_id'] = df_matches['Match ID']\n",
    "    df['map'] = df_matches['Map']\n",
    "    df['team_1_id'] = df_matches['Team 1 ID']\n",
    "    df['team_2_id'] = df_matches['Team 2 ID']\n",
    "    df['team_1_score'] = df_matches['Team 1 Half 1 Score'] + \\\n",
    "        df_matches['Team 1 Half 2 Score'] + df_matches['Team 1 Overtime Score']\n",
    "    df['team_2_score'] = df_matches['Team 2 Half 1 Score'] + \\\n",
    "        df_matches['Team 2 Half 2 Score'] + df_matches['Team 2 Overtime Score']\n",
    "    print('Finished cleaning matches dataset')\n",
    "    return df\n",
    "\n",
    "\n",
    "def decide_winners(dataframe):\n",
    "    for i, row in dataframe.iterrows():\n",
    "        dataframe.set_value(\n",
    "            i, 'winning_team_nr', 1 if row['team_1_score'] > row['team_2_score'] else 2)\n",
    "        dataframe.set_value(\n",
    "            i, 'winning_team_id', row['team_1_id'] if row['team_1_score'] > row['team_2_score'] else row['team_2_id'])\n",
    "    print('Finished deciding winners')\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def calculate_winrate_for_team_on_map(df_total, team_id, map_id):\n",
    "    matches = pd.DataFrame()\n",
    "    won_matches = pd.DataFrame()\n",
    "\n",
    "    df_filtered = df_total.loc[(df_total['team_1_id'] == team_id) & (\n",
    "        df_total['map'] == map_id)]\n",
    "    df_filtered = df_filtered.append(\n",
    "        df_total.loc[(df_total['team_2_id'] == team_id) & (df_total['map'] == map_id)])\n",
    "    matches = matches.append(df_filtered)\n",
    "    won_matches = won_matches.append(df_total.loc[(\n",
    "        df_total['winning_team_id'] == team_id) & (df_total['map'] == map_id)])\n",
    "\n",
    "    return len(won_matches) / len(matches) * 100\n",
    "\n",
    "\n",
    "def calculate_winrate_for_matches(df_total):\n",
    "    already_calculated_keys = {}\n",
    "    for i, row in df_total.iterrows():\n",
    "        team_1_key = str(row['map']) + str(row['team_1_id'])\n",
    "        team_2_key = str(row['map']) + str(row['team_2_id'])\n",
    "        if team_1_key not in already_calculated_keys:\n",
    "            winrate = calculate_winrate_for_team_on_map(\n",
    "                df_total, row['team_1_id'], row['map'])\n",
    "            already_calculated_keys[team_1_key] = winrate\n",
    "            df_total.set_value(i, 'team_1_winrate', winrate)\n",
    "        else:\n",
    "            df_total.set_value(i, 'team_1_winrate',\n",
    "                               already_calculated_keys[team_1_key])\n",
    "        if team_2_key not in already_calculated_keys:\n",
    "            winrate = calculate_winrate_for_team_on_map(\n",
    "                df_total, row['team_2_id'], row['map'])\n",
    "            already_calculated_keys[team_2_key] = winrate\n",
    "            df_total.set_value(i, 'team_2_winrate', winrate)\n",
    "        else:\n",
    "            df_total.set_value(i, 'team_2_winrate',\n",
    "                               already_calculated_keys[team_2_key])\n",
    "    print('Finished calculating winrates')\n",
    "    df_total.to_csv('winrates.csv', index=False)\n",
    "    return df_total\n",
    "\n",
    "\n",
    "def cross_validate(clf, x, y, method_name):\n",
    "    cross_val = KFold(5, shuffle=True, random_state=0)\n",
    "    accuracy_scores = []\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    \n",
    "    for train_index, test_index in cross_val.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy_scores += [accuracy_score(y_test, pred.round())]\n",
    "        recall_scores += [recall_score(y_test, pred.round())]\n",
    "        precision_scores += [precision_score(y_test, pred.round())]\n",
    "\n",
    "    score_string = \"\"\"\n",
    "    ------------------------------------------\n",
    "    {6}:\n",
    "    Accuracy: {0}\n",
    "    Accuracy mean: {1:.3f}\n",
    "\n",
    "    Recall: {2}\n",
    "    Recall mean: {3:.3f}\n",
    "\n",
    "    Precision: {4}\n",
    "    Precision mean: {5:.3f}\n",
    "    ------------------------------------------\n",
    "    \"\"\".format(str(accuracy_scores), \n",
    "               np.mean(accuracy_scores), \n",
    "               str(recall_scores),\n",
    "               np.mean(recall_scores),\n",
    "               str(precision_scores),\n",
    "               np.mean(precision_scores),\n",
    "               method_name)\n",
    "    \n",
    "    print(score_string)\n",
    "\n",
    "\n",
    "def decision_trees(df):\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\", random_state=100,\n",
    "                                 max_depth=3, min_samples_leaf=5)\n",
    "    cross_validate(clf,  df[['team_1_winrate', 'team_2_winrate']].values, df['winning_team_nr'].values, 'Decision trees')\n",
    "\n",
    "\n",
    "def support_vector_machines(df):\n",
    "    clf = svm.SVC()\n",
    "    cross_validate(clf,  df[['team_1_winrate', 'team_2_winrate']].values, df['winning_team_nr'].values, 'Support Vector Machines')\n",
    "   \n",
    "\n",
    "def neural_network_mlp(df):\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                        hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    cross_validate(clf,  df[['team_1_winrate', 'team_2_winrate']].values, df['winning_team_nr'].values, 'Neural Network MLP')\n",
    "\n",
    "\n",
    "def random_forest(df):\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    cross_validate(clf,  df[['team_1_winrate', 'team_2_winrate']].values, df['winning_team_nr'].values, 'Random Forest')\n",
    "    \n",
    "    \n",
    "def linear_regression(df):\n",
    "    clf = LinearRegression()\n",
    "    cross_validate(clf,  df[['team_1_winrate', 'team_2_winrate']].values, df['winning_team_nr'].values, 'Linear Regression')\n",
    "\n",
    "\n",
    "def naive_bayes(df):\n",
    "    clf = GaussianNB()\n",
    "    cross_validate(clf,  df[['team_1_winrate', 'team_2_winrate']].values, df['winning_team_nr'].values, 'Naive Bayes')\n",
    "\n",
    "print('Finished loading functions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cleaning matches dataset\n",
      "Finished deciding winners\n",
      "Finished calculating winrates\n",
      "Finished splitting test and train data\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_data = decide_winners(clean_matches_dataset())\n",
    "df_final_data = calculate_winrate_for_matches(df_cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine and predict by using machine learning classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ------------------------------------------\n",
      "    Decision trees:\n",
      "    Accuracy: [0.70792940591598308, 0.70954511558538402, 0.71995027967681791, 0.71124922311995031, 0.71995027967681791]\n",
      "    Accuracy mean: 0.714\n",
      "\n",
      "    Recall: [0.68853560232870581, 0.72672739391246388, 0.69457262140188969, 0.68183866606579535, 0.69478182636077368]\n",
      "    Recall mean: 0.697\n",
      "\n",
      "    Precision: [0.76227069905800693, 0.74714481498401097, 0.78553677932405563, 0.76860553721107439, 0.77515683814303638]\n",
      "    Precision mean: 0.768\n",
      "    ------------------------------------------\n",
      "    \n",
      "\n",
      "    ------------------------------------------\n",
      "    Support Vector Machines:\n",
      "    Accuracy: [0.72445935868754663, 0.73117076808351977, 0.72964574269732752, 0.72504661280298321, 0.73710379117464264]\n",
      "    Accuracy mean: 0.729\n",
      "\n",
      "    Recall: [0.79064039408866993, 0.81248611419684513, 0.80048341023950775, 0.80013519603424965, 0.81151596941070625]\n",
      "    Recall mean: 0.803\n",
      "\n",
      "    Precision: [0.73363806357781014, 0.734927652733119, 0.74195519348268835, 0.72826086956521741, 0.73858751279426815]\n",
      "    Precision mean: 0.735\n",
      "    ------------------------------------------\n",
      "    \n",
      "\n",
      "    ------------------------------------------\n",
      "    Neural Network MLP:\n",
      "    Accuracy: [0.73191648023862788, 0.73353218990802882, 0.73660658794282163, 0.73113735239279054, 0.74244872591671851]\n",
      "    Accuracy mean: 0.735\n",
      "\n",
      "    Recall: [0.79646215853112401, 0.79871139746722952, 0.78905735003295974, 0.78346101847679139, 0.799370220422852]\n",
      "    Recall mean: 0.793\n",
      "\n",
      "    Precision: [0.74027055150884491, 0.74384440306228017, 0.75600000000000001, 0.74310750160290662, 0.75073933248838187]\n",
      "    Precision mean: 0.747\n",
      "    ------------------------------------------\n",
      "    \n",
      "\n",
      "    ------------------------------------------\n",
      "    Random Forest:\n",
      "    Accuracy: [0.72296793437733031, 0.72433507332836189, 0.71821006836544432, 0.71609695463020506, 0.71062771908017397]\n",
      "    Accuracy mean: 0.718\n",
      "\n",
      "    Recall: [0.83519928347514549, 0.84647856031992885, 0.8914524280377939, 0.83844073907165395, 0.91205578047683311]\n",
      "    Recall mean: 0.865\n",
      "\n",
      "    Precision: [0.71414895653838795, 0.71388420460933111, 0.69588336192109779, 0.70366868381240544, 0.67673564753004001]\n",
      "    Precision mean: 0.701\n",
      "    ------------------------------------------\n",
      "    \n",
      "\n",
      "    ------------------------------------------\n",
      "    Linear Regression:\n",
      "    Accuracy: [0.73340790454884419, 0.7301764852100423, 0.73610938471100062, 0.73387197016780614, 0.7419515226848975]\n",
      "    Accuracy mean: 0.735\n",
      "\n",
      "    Recall: [0.80922525750111962, 0.81093090424350145, 0.79982421445836083, 0.8017124831004957, 0.81488978857399907]\n",
      "    Recall mean: 0.807\n",
      "\n",
      "    Precision: [0.73649887915223156, 0.73440643863179078, 0.75020610057708159, 0.7383274538285951, 0.74302707136997537]\n",
      "    Precision mean: 0.740\n",
      "    ------------------------------------------\n",
      "    \n",
      "\n",
      "    ------------------------------------------\n",
      "    Naive Bayes:\n",
      "    Accuracy: [0.72744220730797915, 0.72532935620183947, 0.72977004350528274, 0.7272840273461777, 0.7346177750155376]\n",
      "    Accuracy mean: 0.729\n",
      "\n",
      "    Recall: [0.80541871921182262, 0.81226394134636748, 0.79784662711491983, 0.79968454258675081, 0.80926675663517766]\n",
      "    Recall mean: 0.805\n",
      "\n",
      "    Precision: [0.73094899410688885, 0.72814180442142995, 0.74329580348004098, 0.73114956736711989, 0.73654042988741042]\n",
      "    Precision mean: 0.734\n",
      "    ------------------------------------------\n",
      "    \n",
      "Finished getting accuracy of all alghoritms\n"
     ]
    }
   ],
   "source": [
    "decision_trees(pd.read_csv('winrates.csv'))\n",
    "support_vector_machines(pd.read_csv('winrates.csv'))\n",
    "neural_network_mlp(pd.read_csv('winrates.csv'))\n",
    "random_forest(pd.read_csv('winrates.csv'))\n",
    "linear_regression(pd.read_csv('winrates.csv'))\n",
    "naive_bayes(pd.read_csv('winrates.csv'))\n",
    "print('Finished getting accuracy of all alghoritms')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
